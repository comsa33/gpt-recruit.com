{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 작업 디렉토리: /workspaces/gpt-recruit-rag/packages/gpt-recruit-rag\n",
      "변경 후 작업 디렉토리: /workspaces/gpt-recruit-rag/packages\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"현재 작업 디렉토리:\", os.getcwd())\n",
    "os.chdir('/workspaces/gpt-recruit-rag/packages/gpt-recruit-rag')  # 프로젝트 루트 디렉토리로 변경\n",
    "print(\"변경 후 작업 디렉토리:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = config[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import format_document\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_elasticsearch import ElasticsearchStore\n",
    "from langchain_community.embeddings import HuggingFaceHubEmbeddings\n",
    "\n",
    "from prompts import CONDENSE_QUESTION_PROMPT, DOCUMENT_PROMPT, LLM_CONTEXT_PROMPT\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url='http://ruoserver.iptime.org:11434/v1/',\n",
    "    model='EEVE-Ko-Q8'\n",
    ")\n",
    "\n",
    "embedding = HuggingFaceHubEmbeddings(model=config[\"EMBEDDING_URI\"])\n",
    "# vectorstore = ElasticsearchStore(\n",
    "#     es_url=config[\"ES_URI\"],\n",
    "#     es_api_key=config[\"ES_API_KEY\"],\n",
    "#     index_name=\"wanted_job_detail_index_v1\",\n",
    "#     vector_query_field='embedding',\n",
    "#     query_field='metadata.position',\n",
    "#     embedding=embedding,\n",
    "#     strategy=ElasticsearchStore.ApproxRetrievalStrategy(\n",
    "#         hybrid=True,\n",
    "#     )\n",
    "# )   # ApproxRetrievalStrategy 사용 (유료 플랜)\n",
    "\n",
    "vectorstore = ElasticsearchStore(\n",
    "    es_url=config[\"ES_URI\"],\n",
    "    es_api_key=config[\"ES_API_KEY\"],\n",
    "    index_name=\"wanted_job_detail_index_v1\",\n",
    "    vector_query_field='embedding',\n",
    "    query_field='metadata.position',\n",
    "    embedding=embedding\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "def _combine_documents(\n",
    "    docs, document_prompt=DOCUMENT_PROMPT, document_separator=\"\\n\\n\"\n",
    "):\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)\n",
    "\n",
    "\n",
    "def _format_chat_history(chat_history: List[Tuple]) -> str:\n",
    "    buffer = \"\"\n",
    "    for dialogue_turn in chat_history:\n",
    "        human = \"Human: \" + dialogue_turn[0]\n",
    "        ai = \"Assistant: \" + dialogue_turn[1]\n",
    "        buffer += \"\\n\" + \"\\n\".join([human, ai])\n",
    "    return buffer\n",
    "\n",
    "\n",
    "class ChainInput(BaseModel):\n",
    "    chat_history: Optional[List[BaseMessage]] = Field(\n",
    "        description=\"Previous chat messages.\"\n",
    "    )\n",
    "    question: str = Field(..., description=\"The question to answer.\")\n",
    "\n",
    "\n",
    "_inputs = RunnableParallel(\n",
    "    standalone_question=RunnablePassthrough.assign(\n",
    "        chat_history=lambda x: _format_chat_history(x[\"chat_history\"])\n",
    "    )\n",
    "    | CONDENSE_QUESTION_PROMPT\n",
    "    | llm\n",
    "    | StrOutputParser(),\n",
    ")\n",
    "\n",
    "_context = {\n",
    "    \"context\": itemgetter(\"standalone_question\") | retriever | _combine_documents,\n",
    "    \"question\": lambda x: x[\"standalone_question\"],\n",
    "}\n",
    "\n",
    "chain = _inputs | _context | LLM_CONTEXT_PROMPT | llm | StrOutputParser()\n",
    "\n",
    "chain = chain.with_types(input_type=ChainInput)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"파이썬 (python) 개발자 채용 정보를 알려주세요.\",\n",
    "    \"오케스트로 회사의 채용 정보를 알려주세요.\",\n",
    "    \"데이터 엔지니어 채용 회사는 어디인가요?\",\n",
    "    \"IT 관련 채용 회사는 어디인가요?\",\n",
    "    \"디자인 관련 채용 회사는 어디인가요?\",\n",
    "    \"마케팅 관련 채용 회사는 어디인가요?\",\n",
    "    \"데이터 관련 채용 회사는 어디인가요?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 딥인사이트 (출처: NAME: 딥인사이트): [질문] IT 분야에서의 채용 회사들은 어디인가요?\n",
      "\n",
      "---\n",
      "딥인사이트는 정보 기술(IT) 분야에서 숙련된 인재를 찾는 회사에 서비스를 제공하는 전문 IT 채용 기업입니다. 다양한 분야의 최고급 소프트웨어 개발자, 디지털 마케팅 전문가, 데이터 분석가 등 뛰어난 인력을 연결하는 데 초점을 맞추고 있습니다. 이 회사는 기업들이 각자의 독특한 요구사항과 목표에 맞는 숙련된 인재를 찾아 팀을 강화할 수 있도록 돕습니다.\n",
      "---\n",
      "\n",
      "2. 코딧(CODITCorp.) (출처: NAME: 코딧(CODITCorp.)): [질문] IT 분야에서의 채용 회사들은 어디인가요?\n",
      "\n",
      "---\n",
      "코딧은 정보 기술 전문가를 찾는 회사에 서비스를 제공하는 선도적인 IT 채용 기업으로, 소프트웨어 개발자부터 사이버보안 전문가, 데이터 과학자까지 다양한 인재를 구인하는 데 도움을 줍니다. 이 회사는 글로벌하게 운영되며 전 세계의 기업들이 숙련된 인력을 효과적으로 찾을 수 있도록 도와 팀을 강화할 수 있습니다.\n",
      "---\n",
      "\n",
      "3. 스마일게이트홀딩스 슈퍼크리에이티브 지점 (출처: NAME: 스마일게이트홀딩스 슈퍼크리에이티브 지점): [질문] IT 분야에서의 채용 회사들은 어디인가요?\n",
      "\n",
      "---\n",
      "스마일게이트홀딩스는 게임 개발과 기술 분야에서 인재를 찾는 회사에 전문 서비스를 제공하는 유망한 IT 채용 기업입니다. 이 회사는 스마일게이트홀딩스의 자회사인 슈퍼크리에이티브의 지점으로, 비디오 게임을 만들고 배포하는 데 필요한 기술과 경험을 가진 인재를 구인하는데 중점을 두고 있습니다.\n",
      "---\n",
      "\n",
      "4. 노타 (출처: NAME: 노타): [질문] IT 분야에서의 채용 회사들은 어디인가요?\n",
      "\n",
      "---\n",
      "노타는 정보 기술 분야에서 숙련된 인력을 찾는 회사에 전문 서비스를 제공하는 선도적인 IT 채용 기업입니다. 소프트웨어 개발자, 데이터 분석가, 사이버보안 전문가 등 다양한 인재를 구인하는데 도움을 주며, 기업들은 이 회사의 전문성을 활용하여 자신의 독특한 요구사항에 맞는 최적의 인재를 찾을 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"question\": questions[0],\n",
    "        \"chat_history\": [],\n",
    "    }\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "follow_up_question = \"파이썬 개발자를 채용하는 회사의 채용공고를 확인하고, 그 중 한 곳 회사의 적합한 한국식 자기소개서를 작성해주세요.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 스마일게이트홀딩스 슈퍼크리에이티브 지점 (PASSAGE): 이 회사는 모바일 및 콘솔 게임 개발을 위한 '게임 디자이너', '게임 프로그래머' 그리고 다양한 분야의 'QA 테스터'를 채용하고 있습니다. 이들은 훌륭한 커뮤니케이션 기술, 강한 문제해결 능력, 게임 산업에 대한 열정을 가진 사람을 찾고 있습니다 (출처: [1]).\n",
      "2. 베이글코드(Bagelcode) (PASSAGE): 그들은 모바일 게임에 특화된 '게임 디자이너', '게임 프로그래머' 및 'QA 테스터'를 찾고 있습니다. 또한 마케팅 분야에는 '마케터/콘텐츠 기획자'와 사업 개발 분야에서 '사업 개발 매니저(BD)'가 필요합니다 (출처: [2]).\n",
      "3. 메디테라피 (PASSAGE): 이 회사는 제품 관리 분야에서 '제품 소유자'를 찾고 있습니다. 또한 게임 디자인과 프로그래밍을 위한 전문가들을 필요로 하며, 모바일 게임에 특화된 '게임 디자이너', '게임 프로그래머' 그리고 QA 분야에서의 'QA 테스터'를 원합니다 (출처: [3]).\n",
      "4. 코딧(CODITCorp.) (PASSAGE): 게임 개발 분야에서 '게임 디자이너', '게임 아티스트', '게임 프로그래머' 그리고 모바일 게임의 질 관리를 위한 'QA 테스터'의 지원을 받고 있습니다. 또한, 그들은 마케팅 팀에 대한 '콘텐츠 기획자', 사업 개발 분야의 '사업 개발 매니저(BD)', 그리고 그들의 인사 부서에서 'HR 채용 담당자'도 찾고 있습니다 (출처: [4]).\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"question\": follow_up_question,\n",
    "        \"chat_history\": [\n",
    "            questions[0],\n",
    "            response,\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthorizationException",
     "evalue": "AuthorizationException(403, 'security_exception', 'current license is non-compliant for [Reciprocal Rank Fusion (RRF)]')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthorizationException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chain\u001b[38;5;241m.\u001b[39mastream(\n\u001b[1;32m      3\u001b[0m     {\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: questions[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m      6\u001b[0m     }\n\u001b[1;32m      7\u001b[0m ):\n\u001b[1;32m      8\u001b[0m     chunks\u001b[38;5;241m.\u001b[39mappend(chunk)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(chunk, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:4712\u001b[0m, in \u001b[0;36mRunnableBindingBase.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4706\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mastream\u001b[39m(\n\u001b[1;32m   4707\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4708\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   4709\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4710\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   4711\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 4712\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39mastream(\n\u001b[1;32m   4713\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   4714\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   4715\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[1;32m   4716\u001b[0m     ):\n\u001b[1;32m   4717\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:2900\u001b[0m, in \u001b[0;36mRunnableSequence.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2897\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minput_aiter\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[Input]:\n\u001b[1;32m   2898\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m-> 2900\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matransform(input_aiter(), config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   2901\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:2883\u001b[0m, in \u001b[0;36mRunnableSequence.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2877\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21matransform\u001b[39m(\n\u001b[1;32m   2878\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2879\u001b[0m     \u001b[38;5;28minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   2880\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2881\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2882\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 2883\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_atransform_stream_with_config(\n\u001b[1;32m   2884\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2885\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_atransform,\n\u001b[1;32m   2886\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m   2887\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2888\u001b[0m     ):\n\u001b[1;32m   2889\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:1985\u001b[0m, in \u001b[0;36mRunnable._atransform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1980\u001b[0m     chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1981\u001b[0m         py_anext(iterator),  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1982\u001b[0m         context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m   1983\u001b[0m     )\n\u001b[1;32m   1984\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1985\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m cast(Output, \u001b[38;5;28;01mawait\u001b[39;00m py_anext(iterator))\n\u001b[1;32m   1986\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   1987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:2853\u001b[0m, in \u001b[0;36mRunnableSequence._atransform\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m steps:\n\u001b[1;32m   2846\u001b[0m     final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39matransform(\n\u001b[1;32m   2847\u001b[0m         final_pipeline,\n\u001b[1;32m   2848\u001b[0m         patch_config(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2851\u001b[0m         ),\n\u001b[1;32m   2852\u001b[0m     )\n\u001b[0;32m-> 2853\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m final_pipeline:\n\u001b[1;32m   2854\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m output\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/output_parsers/transform.py:60\u001b[0m, in \u001b[0;36mBaseTransformOutputParser.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21matransform\u001b[39m(\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28minput\u001b[39m: AsyncIterator[Union[\u001b[38;5;28mstr\u001b[39m, BaseMessage]],\n\u001b[1;32m     57\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m     59\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[T]:\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_atransform_stream_with_config(\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_atransform, config, run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     62\u001b[0m     ):\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:1944\u001b[0m, in \u001b[0;36mRunnable._atransform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1942\u001b[0m input_for_tracing, input_for_transform \u001b[38;5;241m=\u001b[39m atee(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   1943\u001b[0m \u001b[38;5;66;03m# Start the input iterator to ensure the input runnable starts before this one\u001b[39;00m\n\u001b[0;32m-> 1944\u001b[0m final_input: Optional[Input] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m py_anext(input_for_tracing, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1945\u001b[0m final_input_supported \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1946\u001b[0m final_output: Optional[Output] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/utils/aiter.py:62\u001b[0m, in \u001b[0;36mpy_anext.<locals>.anext_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manext_impl\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[T, Any]:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;66;03m# The C code is way more low-level than this, as it implements\u001b[39;00m\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;66;03m# all methods of the iterator protocol. In this implementation\u001b[39;00m\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;66;03m# we're relying on higher-level coroutine concepts, but that's\u001b[39;00m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;66;03m# exactly what we want -- crosstest pure-Python high-level\u001b[39;00m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;66;03m# implementation and low-level C anext() iterators.\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;21m__anext__\u001b[39m(iterator)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m default\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/utils/aiter.py:97\u001b[0m, in \u001b[0;36mtee_peer\u001b[0;34m(iterator, buffer, peers, lock)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m iterator\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__anext__\u001b[39m()\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:1316\u001b[0m, in \u001b[0;36mRunnable.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1313\u001b[0m final: Input\n\u001b[1;32m   1314\u001b[0m got_first_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1316\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m ichunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28minput\u001b[39m:\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;66;03m# The default implementation of transform is to buffer input and\u001b[39;00m\n\u001b[1;32m   1318\u001b[0m     \u001b[38;5;66;03m# then call stream.\u001b[39;00m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;66;03m# It'll attempt to gather all input into a single chunk using\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;66;03m# the `+` operator.\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;66;03m# If the input is not addable, then we'll assume that we can\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;66;03m# only operate on the last chunk,\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# and we'll iterate until we get to the last chunk.\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m got_first_val:\n\u001b[1;32m   1325\u001b[0m         final \u001b[38;5;241m=\u001b[39m ichunk\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:1316\u001b[0m, in \u001b[0;36mRunnable.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1313\u001b[0m final: Input\n\u001b[1;32m   1314\u001b[0m got_first_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1316\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m ichunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28minput\u001b[39m:\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;66;03m# The default implementation of transform is to buffer input and\u001b[39;00m\n\u001b[1;32m   1318\u001b[0m     \u001b[38;5;66;03m# then call stream.\u001b[39;00m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;66;03m# It'll attempt to gather all input into a single chunk using\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;66;03m# the `+` operator.\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;66;03m# If the input is not addable, then we'll assume that we can\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;66;03m# only operate on the last chunk,\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# and we'll iterate until we get to the last chunk.\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m got_first_val:\n\u001b[1;32m   1325\u001b[0m         final \u001b[38;5;241m=\u001b[39m ichunk\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:3315\u001b[0m, in \u001b[0;36mRunnableParallel.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3309\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21matransform\u001b[39m(\n\u001b[1;32m   3310\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3311\u001b[0m     \u001b[38;5;28minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   3312\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3313\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   3314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m-> 3315\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_atransform_stream_with_config(\n\u001b[1;32m   3316\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_atransform, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   3317\u001b[0m     ):\n\u001b[1;32m   3318\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:1985\u001b[0m, in \u001b[0;36mRunnable._atransform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1980\u001b[0m     chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1981\u001b[0m         py_anext(iterator),  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1982\u001b[0m         context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m   1983\u001b[0m     )\n\u001b[1;32m   1984\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1985\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m cast(Output, \u001b[38;5;28;01mawait\u001b[39;00m py_anext(iterator))\n\u001b[1;32m   1986\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   1987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:3302\u001b[0m, in \u001b[0;36mRunnableParallel._atransform\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   3300\u001b[0m (step_name, generator) \u001b[38;5;241m=\u001b[39m tasks\u001b[38;5;241m.\u001b[39mpop(task)\n\u001b[1;32m   3301\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3302\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m AddableDict({step_name: \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m})\n\u001b[1;32m   3303\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   3304\u001b[0m     new_task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(get_next_chunk(generator))\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:3285\u001b[0m, in \u001b[0;36mRunnableParallel._atransform.<locals>.get_next_chunk\u001b[0;34m(generator)\u001b[0m\n\u001b[1;32m   3284\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_next_chunk\u001b[39m(generator: AsyncIterator) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Output]:\n\u001b[0;32m-> 3285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m py_anext(generator)\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:2883\u001b[0m, in \u001b[0;36mRunnableSequence.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2877\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21matransform\u001b[39m(\n\u001b[1;32m   2878\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2879\u001b[0m     \u001b[38;5;28minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   2880\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2881\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2882\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 2883\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_atransform_stream_with_config(\n\u001b[1;32m   2884\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2885\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_atransform,\n\u001b[1;32m   2886\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m   2887\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2888\u001b[0m     ):\n\u001b[1;32m   2889\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:1985\u001b[0m, in \u001b[0;36mRunnable._atransform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1980\u001b[0m     chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1981\u001b[0m         py_anext(iterator),  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1982\u001b[0m         context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m   1983\u001b[0m     )\n\u001b[1;32m   1984\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1985\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m cast(Output, \u001b[38;5;28;01mawait\u001b[39;00m py_anext(iterator))\n\u001b[1;32m   1986\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   1987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:2853\u001b[0m, in \u001b[0;36mRunnableSequence._atransform\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m steps:\n\u001b[1;32m   2846\u001b[0m     final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39matransform(\n\u001b[1;32m   2847\u001b[0m         final_pipeline,\n\u001b[1;32m   2848\u001b[0m         patch_config(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2851\u001b[0m         ),\n\u001b[1;32m   2852\u001b[0m     )\n\u001b[0;32m-> 2853\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m final_pipeline:\n\u001b[1;32m   2854\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m output\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:4180\u001b[0m, in \u001b[0;36mRunnableLambda.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4174\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21matransform\u001b[39m(\n\u001b[1;32m   4175\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4176\u001b[0m     \u001b[38;5;28minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   4177\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4178\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   4179\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 4180\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_atransform_stream_with_config(\n\u001b[1;32m   4181\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   4182\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_atransform,\n\u001b[1;32m   4183\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config(config, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafunc \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mafunc\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc),\n\u001b[1;32m   4184\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4185\u001b[0m     ):\n\u001b[1;32m   4186\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m output\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:1944\u001b[0m, in \u001b[0;36mRunnable._atransform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1942\u001b[0m input_for_tracing, input_for_transform \u001b[38;5;241m=\u001b[39m atee(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   1943\u001b[0m \u001b[38;5;66;03m# Start the input iterator to ensure the input runnable starts before this one\u001b[39;00m\n\u001b[0;32m-> 1944\u001b[0m final_input: Optional[Input] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m py_anext(input_for_tracing, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1945\u001b[0m final_input_supported \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1946\u001b[0m final_output: Optional[Output] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/utils/aiter.py:62\u001b[0m, in \u001b[0;36mpy_anext.<locals>.anext_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manext_impl\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[T, Any]:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;66;03m# The C code is way more low-level than this, as it implements\u001b[39;00m\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;66;03m# all methods of the iterator protocol. In this implementation\u001b[39;00m\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;66;03m# we're relying on higher-level coroutine concepts, but that's\u001b[39;00m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;66;03m# exactly what we want -- crosstest pure-Python high-level\u001b[39;00m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;66;03m# implementation and low-level C anext() iterators.\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;21m__anext__\u001b[39m(iterator)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m default\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/utils/aiter.py:97\u001b[0m, in \u001b[0;36mtee_peer\u001b[0;34m(iterator, buffer, peers, lock)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m iterator\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__anext__\u001b[39m()\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:1334\u001b[0m, in \u001b[0;36mRunnable.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1331\u001b[0m             final \u001b[38;5;241m=\u001b[39m ichunk\n\u001b[1;32m   1333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[0;32m-> 1334\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mastream(final, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1335\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m output\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:819\u001b[0m, in \u001b[0;36mRunnable.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mastream\u001b[39m(\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m    812\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m    814\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[Output]:\n\u001b[1;32m    815\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;124;03m    Default implementation of astream, which calls ainvoke.\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;124;03m    Subclasses should override this method if they support streaming output.\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 819\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/retrievers.py:228\u001b[0m, in \u001b[0;36mBaseRetriever.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Asynchronously invoke the retriever to get relevant documents.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \n\u001b[1;32m    211\u001b[0m \u001b[38;5;124;03mMain entry point for asynchronous retriever invocations.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m    await retriever.ainvoke(\"query\")\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    227\u001b[0m config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m--> 228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maget_relevant_documents(\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    230\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    231\u001b[0m     tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    232\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    233\u001b[0m     run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    235\u001b[0m )\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:157\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.awarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     emit_warning()\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/retrievers.py:387\u001b[0m, in \u001b[0;36mBaseRetriever.aget_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[1;32m    390\u001b[0m         result,\n\u001b[1;32m    391\u001b[0m     )\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/retrievers.py:380\u001b[0m, in \u001b[0;36mBaseRetriever.aget_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[0;32m--> 380\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aget_relevant_documents(\n\u001b[1;32m    381\u001b[0m         query, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs\n\u001b[1;32m    382\u001b[0m     )\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aget_relevant_documents(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/vectorstores.py:716\u001b[0m, in \u001b[0;36mVectorStoreRetriever._aget_relevant_documents\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_aget_relevant_documents\u001b[39m(\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m, run_manager: AsyncCallbackManagerForRetrieverRun\n\u001b[1;32m    714\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 716\u001b[0m         docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39masimilarity_search(\n\u001b[1;32m    717\u001b[0m             query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_kwargs\n\u001b[1;32m    718\u001b[0m         )\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity_score_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    720\u001b[0m         docs_and_similarities \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    721\u001b[0m             \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39masimilarity_search_with_relevance_scores(\n\u001b[1;32m    722\u001b[0m                 query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_kwargs\n\u001b[1;32m    723\u001b[0m             )\n\u001b[1;32m    724\u001b[0m         )\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/vectorstores.py:403\u001b[0m, in \u001b[0;36mVectorStore.asimilarity_search\u001b[0;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return docs most similar to query.\"\"\"\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;66;03m# This is a temporary workaround to make the similarity search\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;66;03m# asynchronous. The proper solution is to make the similarity search\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;66;03m# asynchronous in the vector store implementations.\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m run_in_executor(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimilarity_search, query, k\u001b[38;5;241m=\u001b[39mk, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_core/runnables/config.py:514\u001b[0m, in \u001b[0;36mrun_in_executor\u001b[0;34m(executor_or_config, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run a function in an executor.\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \n\u001b[1;32m    503\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03m    Output: The output of the function.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m executor_or_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(executor_or_config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;66;03m# Use default executor with context copied from current context\u001b[39;00m\n\u001b[0;32m--> 514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mget_running_loop()\u001b[38;5;241m.\u001b[39mrun_in_executor(\n\u001b[1;32m    515\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    516\u001b[0m         cast(Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, T], partial(copy_context()\u001b[38;5;241m.\u001b[39mrun, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)),\n\u001b[1;32m    517\u001b[0m     )\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mget_running_loop()\u001b[38;5;241m.\u001b[39mrun_in_executor(\n\u001b[1;32m    520\u001b[0m     executor_or_config, partial(func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs\n\u001b[1;32m    521\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_elasticsearch/vectorstores.py:698\u001b[0m, in \u001b[0;36mElasticsearchStore.similarity_search\u001b[0;34m(self, query, k, fetch_k, filter, **kwargs)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search\u001b[39m(\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    679\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    684\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    685\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return Elasticsearch documents most similar to query.\u001b[39;00m\n\u001b[1;32m    686\u001b[0m \n\u001b[1;32m    687\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;124;03m        in descending order of similarity.\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 698\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfetch_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m results]\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/langchain_elasticsearch/vectorstores.py:881\u001b[0m, in \u001b[0;36mElasticsearchStore._search\u001b[0;34m(self, query, k, query_vector, fetch_k, fields, filter, custom_query, doc_builder, **kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling custom_query, Query body now: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery_body\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    880\u001b[0m \u001b[38;5;66;03m# Perform the kNN search on the Elasticsearch index and return the results.\u001b[39;00m\n\u001b[0;32m--> 881\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mquery_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_includes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_doc_builder\u001b[39m(hit: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Document:\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Document(\n\u001b[1;32m    891\u001b[0m         page_content\u001b[38;5;241m=\u001b[39mhit[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_source\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_field, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    892\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mhit[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_source\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}),\n\u001b[1;32m    893\u001b[0m     )\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py:446\u001b[0m, in \u001b[0;36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    444\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/elasticsearch/_sync/client/__init__.py:4091\u001b[0m, in \u001b[0;36mElasticsearch.search\u001b[0;34m(self, index, aggregations, aggs, allow_no_indices, allow_partial_search_results, analyze_wildcard, analyzer, batched_reduce_size, ccs_minimize_roundtrips, collapse, default_operator, df, docvalue_fields, error_trace, expand_wildcards, explain, ext, fields, filter_path, from_, highlight, human, ignore_throttled, ignore_unavailable, indices_boost, knn, lenient, max_concurrent_shard_requests, min_compatible_shard_node, min_score, pit, post_filter, pre_filter_shard_size, preference, pretty, profile, q, query, rank, request_cache, rescore, rest_total_hits_as_int, routing, runtime_mappings, script_fields, scroll, search_after, search_type, seq_no_primary_term, size, slice, sort, source, source_excludes, source_includes, stats, stored_fields, suggest, suggest_field, suggest_mode, suggest_size, suggest_text, terminate_after, timeout, track_scores, track_total_hits, typed_keys, version, body)\u001b[0m\n\u001b[1;32m   4089\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m __body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4090\u001b[0m     __headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 4091\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m   4092\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4093\u001b[0m \u001b[43m    \u001b[49m\u001b[43m__path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msearch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_parts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__path_parts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4099\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py:271\u001b[0m, in \u001b[0;36mBaseClient.perform_request\u001b[0;34m(self, method, path, params, headers, body, endpoint_id, path_parts)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperform_request\u001b[39m(\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    257\u001b[0m     method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    264\u001b[0m     path_parts: Optional[Mapping[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    265\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ApiResponse[Any]:\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_otel\u001b[38;5;241m.\u001b[39mspan(\n\u001b[1;32m    267\u001b[0m         method,\n\u001b[1;32m    268\u001b[0m         endpoint_id\u001b[38;5;241m=\u001b[39mendpoint_id,\n\u001b[1;32m    269\u001b[0m         path_parts\u001b[38;5;241m=\u001b[39mpath_parts \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[1;32m    270\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m otel_span:\n\u001b[0;32m--> 271\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43motel_span\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43motel_span\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m         otel_span\u001b[38;5;241m.\u001b[39mset_elastic_cloud_metadata(response\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mheaders)\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/workspaces/gpt-recruit-rag/.venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py:352\u001b[0m, in \u001b[0;36mBaseClient._perform_request\u001b[0;34m(self, method, path, params, headers, body, otel_span)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    350\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTP_EXCEPTIONS\u001b[38;5;241m.\u001b[39mget(meta\u001b[38;5;241m.\u001b[39mstatus, ApiError)(\n\u001b[1;32m    353\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage, meta\u001b[38;5;241m=\u001b[39mmeta, body\u001b[38;5;241m=\u001b[39mresp_body\n\u001b[1;32m    354\u001b[0m     )\n\u001b[1;32m    356\u001b[0m \u001b[38;5;66;03m# 'X-Elastic-Product: Elasticsearch' should be on every 2XX response.\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verified_elasticsearch:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;66;03m# If the header is set we mark the server as verified.\u001b[39;00m\n",
      "\u001b[0;31mAuthorizationException\u001b[0m: AuthorizationException(403, 'security_exception', 'current license is non-compliant for [Reciprocal Rank Fusion (RRF)]')"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "async for chunk in chain.astream(\n",
    "    {\n",
    "        \"question\": questions[0],\n",
    "        \"chat_history\": [],\n",
    "    }\n",
    "):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ''.join(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "회사명: 에잇퍼센트 (8Percent)\n",
      "직무명: 파이썬 개발자\n",
      "제목: 파이썬 개발자로서의 열정 및 전문성과 함께하는 에잇퍼센트 입사를 희망하며\n",
      "\n",
      "안녕하세요. 존경하는 여러분,\n",
      "\n",
      "저는 유연한 문제 해결 능력을 가진 파이썬 전문 개발자로, 에잇퍼센트에 합류하고자 열정을 가득 담아 지원합니다. 오픈소스 기술 채택을 통해 혁신을 주도하고 긍정적인 영향을 끼치는 데 전념하는 에잇퍼센트의 가치와 제 개인적 신념이 완벽하게 부합한다고 믿으며 이 자리가 저의 기술과 경험과 잘 어울린다고 확신합니다.\n",
      "\n",
      "다양한 산업 분야에서 근무하며 소프트웨어 솔루션을 개발하는 방대한 경력을 바탕으로, 파이썬 개발에 대한 열정을 키우고 최신 프레임워크와 도구에 능숙해졌습니다. 복잡한 시스템을 이해하고 고성능의 확장 가능한 애플리케이션을 만드는 데에 있어 탁월한 실력을 보유하고 있습니다. 또한 애자일 방법론을 준수하며 팀워크와 협업 정신을 소중히 여깁니다.\n",
      "\n",
      "프로젝트 관리, API 통합 및 소프트웨어 아키텍처에 대한 제 경험은 에잇퍼센트의 현 기술 스택에 큰 가치가 될 것이며, 새로운 개발자들이 성장하도록 돕고 조직 전체의 생산성과 효율성에 기여하고자 합니다.\n",
      "\n",
      "에잇퍼센트에서는 윤리적이고 사회적 책임을 다하는 기업으로서 소프트웨어 솔루션을 제공함으로써 사회에 실질적인 차이를 만들어 낼 수 있는 기회가 있다고 생각합니다. 에잇퍼센트의 팀에 합류하여 제 기술과 전문성을 기여하고 혁신과 번영의 문화를 계속해서 증진시키고자 합니다.\n",
      "\n",
      "제 자격, 열정 및 파이썬 개발 분야의 전문 지식을 고려하여 이 포지션에 지원하게 되었습니다. 이 기회를 주셔서 감사하며, 저를 더 잘 알아가고 에잇퍼센트에 기여할 수 있는 방안을 논의하기를 기대합니다.\n",
      "\n",
      "감사합니다,\n",
      "\n",
      "[당신의 이름]"
     ]
    }
   ],
   "source": [
    "chunks2 = []\n",
    "async for chunk in chain.astream(\n",
    "    {\n",
    "        \"question\": follow_up_question,\n",
    "        \"chat_history\": [\n",
    "            questions[0],\n",
    "            response,\n",
    "        ],\n",
    "    }\n",
    "):\n",
    "    chunks2.append(chunk)\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
